<p align="center">
  <h3 align="center"><strong>Progressive Detail Injection for Accurate T2I Generation</strong></h3>
  
<div align="center">
<a href='https://prot2i.github.io/'><img src='https://img.shields.io/badge/Project-Page-Green'></a> &nbsp;&nbsp;&nbsp;&nbsp;
<br>
</div>

<p align="center">
    <img src="assets/teaser.png" alt="teaser" width="1024px" />
</p>

## ToDo List
- [ ] Publish extension methods in combination with control-net.
- [X] Publish notebooks for visualization.
- [X] Publish the complete code.

## Overview
### Abstract
Text-to-image (T2I) generation has made significant strides in recent years, yet challenges remain, particularly when handling long and complex textual descriptions. Existing models often struggle to accurately map intricate text prompts to coherent and high-quality visual representations, leading to issues such as the loss of important subjects, attribute confusion, and incoherent images. These issues are amplified as the complexity and length of the prompts increase. To address these limitations, we propose a novel training-free approach for accurate **T2I** generation, called **Pro**gressive detail injection (**ProT2I**), which improves the generation of images from complex, multi-subject prompts. Our method decomposes complex prompts into progressively detailed versions, utilizing a multi-branch network that processes these versions in parallel. A novel attention propagation mechanism ensures the accurate injection of detailed attributes into their corresponding regions, effectively preserving both global structure and fine-grained details. The flexibility of our approach allows it to be seamlessly integrated with existing state-of-the-art T2I models as a plug-and-play enhancement. Extensive experiments on public benchmarks demonstrate that our method outperforms existing models in terms of text alignment and image quality, effectively mitigating attribute confusion and maintaining high-fidelity generation.
### Method
<p align="center">
    <img src="assets/paradigm.png" alt="paradigm" width="1024px" />
</p>

## Setup
This code is based on parallel inference of stable diffusion models. 
Here we offer two versions of the code based on SD1.5 and SDXL separately, but our method can be extended to many pre-trained models as a plug-and-play module. 
Emperically, **one branch generation** (at 512x512 resolution) costs approximately **2.3GB** VRAM in SD1.5; for SDXL, **one branch generation** (at 1024x1024 resolution) costs approximately **13.4GB** VRAM.
Due to the flexibility of our method, the number of attributes of each branch can be freely adjusted, where a branch represents an image generated by a sub-prompt.
ChatGPT automatic parsing is supported in our code, which can be seen in [run_sd1_5.py](https://github.com/CONSTANT1386/Progress-Detail-Injection-for-Accurate-T2I-Generation/blob/main/run_sd1_5.py). However, **we strongly recommend that you decompose the sentences manually** due to the unstable output of the api invoke,
detailed in [run_sd1_5_manual_decomposition.py](https://github.com/CONSTANT1386/Progress-Detail-Injection-for-Accurate-T2I-Generation/blob/main/run_sd1_5_manual_decomposition.py) and [run_sdxl_mannual_decomposition.py](https://github.com/CONSTANT1386/Progress-Detail-Injection-for-Accurate-T2I-Generation/blob/main/run_sdxl_mannual_decomposition.py).

We also offer two notebooks ([ProT2I SD1_5 notebook.ipynb](https://github.com/CONSTANT1386/Progress-Detail-Injection-for-Accurate-T2I-Generation/blob/main/ProT2I%20SD1_5%20notebook.ipynb) and [ProT2I SDXL notebook.ipynb](https://github.com/CONSTANT1386/Progress-Detail-Injection-for-Accurate-T2I-Generation/blob/main/ProT2I%20SDXL%20notebook.ipynb)) to visualise the method and **visualise the corresponding Self Attention Map and Cross Attention Map separately in the generation process**.

## Extension
ðŸ”¥ðŸ”¥ Due to the flexibility of our method, it can be easily integrated many other plug-and-play modules, which will provide many possibilities. Here are a sequence of images demonstrating its flexibility when combining with control-net.
<p align="center">
    <img src="assets/with controlnet.jpg" alt="extension image" width="1024px" />
</p>
